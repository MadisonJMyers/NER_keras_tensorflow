{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmyers/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "# from keras.layers import Flatten, Dense, Embedding, Dropout, Bidirectional, LSTM, Concatenate, Reshape, Lambda, Input, Activation\n",
    "# from keras.layers.merge import concatenate\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.preprocessing.text import one_hot\n",
    "# from keras.utils import np_utils\n",
    "# from keras_contrib.layers import CRF\n",
    "# from model.data_utils import get_trimmed_glove_vectors, load_vocab, get_processing_word, CoNLLDataset, get_trimmed_glove_vectors, load_vocab, get_processing_word, minibatches, get_chunks, pad_sequences\n",
    "# from model.ner_model import NERModel\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Embedding, Dropout, Bidirectional, LSTM, Concatenate, Reshape, Lambda, Input, Activation, Masking\n",
    "from tensorflow.python.keras.layers import concatenate\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import one_hot\n",
    "from keras_contrib.layers import CRF\n",
    "from model.data_utils import get_trimmed_glove_vectors, load_vocab, get_processing_word, CoNLLDataset, get_trimmed_glove_vectors, load_vocab, get_processing_word, minibatches, get_chunks, pad_sequences\n",
    "from model.ner_model import NERModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download new data\n",
    "#source: https://github.com/synalp/NER\n",
    "train_filename = \"data/coNLL/eng/eng.train.iob\"\n",
    "dev_filename = \"data/coNLL/eng/eng.testa.iob\"\n",
    "test_filename = \"data/coNLL/eng/eng.testb.iob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.count>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filename.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_chars = True\n",
    "max_iter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$NUM$': 13,\n",
       " '$UNK$': 9,\n",
       " '.': 16,\n",
       " 'a': 11,\n",
       " 'actor': 2,\n",
       " 'american': 4,\n",
       " 'an': 8,\n",
       " 'and': 0,\n",
       " 'economic': 12,\n",
       " 'european': 22,\n",
       " 'french': 7,\n",
       " 'in': 5,\n",
       " 'is': 1,\n",
       " 'jean': 10,\n",
       " 'lives': 21,\n",
       " 'new': 19,\n",
       " 'oscar': 20,\n",
       " 'pierre': 14,\n",
       " 'political': 17,\n",
       " 'the': 3,\n",
       " 'union': 6,\n",
       " 'won': 18,\n",
       " 'york': 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_words = load_vocab(\"data/words.txt\")\n",
    "vocab_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 23,\n",
       " 'A': 5,\n",
       " 'E': 17,\n",
       " 'F': 9,\n",
       " 'J': 18,\n",
       " 'N': 8,\n",
       " 'P': 25,\n",
       " 'T': 20,\n",
       " 'U': 21,\n",
       " 'Y': 3,\n",
       " 'a': 15,\n",
       " 'c': 27,\n",
       " 'd': 11,\n",
       " 'e': 7,\n",
       " 'h': 24,\n",
       " 'i': 10,\n",
       " 'k': 16,\n",
       " 'l': 1,\n",
       " 'm': 26,\n",
       " 'n': 12,\n",
       " 'o': 14,\n",
       " 'p': 22,\n",
       " 'r': 4,\n",
       " 's': 13,\n",
       " 't': 6,\n",
       " 'u': 19,\n",
       " 'v': 2,\n",
       " 'w': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_chars = load_vocab(\"data/chars.txt\")\n",
    "vocab_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LOC': 7,\n",
       " 'B-MISC': 3,\n",
       " 'B-ORG': 5,\n",
       " 'B-PER': 1,\n",
       " 'I-LOC': 8,\n",
       " 'I-MISC': 4,\n",
       " 'I-ORG': 6,\n",
       " 'I-PER': 2,\n",
       " 'O': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: this order could be arbitrary, with values in the interval [0, num_tags]\n",
    "# ALSO: there should be a difference between a null tag, and a padded label\n",
    "vocab_tags = load_vocab(\"data/tags.txt\")\n",
    "# vocab_tags = { #maybe try a blank line or just 0 or set 0 equal to 0?\n",
    "#         'O': 1,\n",
    "#         'B-PER': 2,\n",
    "#         'I-PER': 3,\n",
    "#         'B-MISC': 4,\n",
    "#         'I-MISC': 5,\n",
    "#         'B-ORG': 6,\n",
    "#         'I-ORG': 7,\n",
    "#         'B-LOC': 8,\n",
    "#         'I-LOC': 9\n",
    "#     }\n",
    "vocab_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_char = len(vocab_chars)\n",
    "n_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = (len(vocab_tags)+1) #+1 if different vocab_tags\n",
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coNLL data for validation\n",
    "dev = CoNLLDataset(dev_filename, get_processing_word(vocab_words, vocab_chars,lowercase=True, chars=use_chars),\n",
    "                  get_processing_word(vocab_tags, lowercase=False, allow_unk=False), max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coNLL data for train\n",
    "train = CoNLLDataset(train_filename, get_processing_word(vocab_words, vocab_chars,lowercase=True, chars=use_chars),\n",
    "                  get_processing_word(vocab_tags, lowercase=False, allow_unk=False), max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coNLL data for test\n",
    "test = CoNLLDataset(test_filename, get_processing_word(vocab_words, vocab_chars,lowercase=True, chars=use_chars),\n",
    "                  get_processing_word(vocab_tags, lowercase=False, allow_unk=False), max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model.data_utils.CoNLLDataset at 0x7fbf22c03710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_vocab(filename):\n",
    "    \"\"\"Load vocab from file\n",
    "    Args:\n",
    "        filename: path to the glove vectors\n",
    "    Returns:\n",
    "        vocab: set() of strings\n",
    "    \"\"\"\n",
    "    print(\"Building vocab...\")\n",
    "    vocab = set()\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            word = line.strip().split(' ')[0]\n",
    "            vocab.add(word)\n",
    "    print(\"- done. {} tokens\".format(len(vocab)))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_data = np.load(\"data/glove.6B.300d.trimmed.npz\")\n",
    "# vocab_glove = get_glove_vocab(\"data/glove.6B.300d.trimmed.npz\")\n",
    "# vocab = vocab_words & vocab_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_data = get_glove_vocab(\"data/glove.6B.300d.trimmed.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = emb_data[\"embeddings\"]\n",
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_word = 300 #End to end paper uses 30\n",
    "dim_char = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size_char = 100 # lstm on chars\n",
    "hidden_size_lstm = 300 # lstm on word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0105 #0.001 #End to end uses learning rate of 0.01 for POS tagging and 0.015 for NER where lr is updated on each epoch with decay rate 0.05\n",
    "#End to end also uses gradient clipping of 5.0\n",
    "lr_decay = 0.0005 #GG uses 0.9; paper uses 0.05\n",
    "nepochs = 75 #End to end paper saw best results at 50 epochs\n",
    "batch_size = 10 #20 #End to end paper uses 10 #eval at 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make use of minibatches with fit_generator\n",
    "# for i, (words, labels) in enumerate(minibatches(train, batch_size)):\n",
    "words, labels = list(minibatches(train, len(train)))[0]  # NOTE: len(train) will return entire dataset!\n",
    "#GG's version\n",
    "char_ids, word_ids = zip(*words)\n",
    "word_ids, sequence_lengths = pad_sequences(word_ids, pad_tok=9) #word_ids = vocab_chars?\n",
    "char_ids, word_lengths = pad_sequences(char_ids, pad_tok=9, nlevels=2)\n",
    "labels, _ = pad_sequences(labels, pad_tok=9)\n",
    "#try with maxlengths\n",
    "# char_ids, word_ids = zip(*words)\n",
    "# word_ids, max_seq_length_b = pad_sequences(word_ids, pad_tok=0) #word_ids = vocab_chars?\n",
    "# char_ids, max_word_length_b = pad_sequences(char_ids, pad_tok=0, nlevels=2)\n",
    "# labels, _ = pad_sequences(labels, pad_tok=0)\n",
    "#try with keras definition of pad_sequences\n",
    "# char_ids, word_ids = zip(*words)\n",
    "# word_ids = pad_sequences(word_ids, padding='post', value=0, maxlen=max_seq_length) #word_ids = vocab_chars?\n",
    "# char_ids= pad_sequences(char_ids, padding='post', value=0)#, maxlen=max_word_length)\n",
    "# labels = pad_sequences(labels, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 113)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids_array = np.array(word_ids)\n",
    "word_ids_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE PADDING VALUE FOR VAL & TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation/dev\n",
    "\n",
    "words_dev, labels_dev = list(minibatches(dev, len(dev)))[0]  \n",
    "char_ids_dev, word_ids_dev = zip(*words_dev)\n",
    "word_ids_dev, sequence_lengths_dev = pad_sequences(word_ids_dev, 0)\n",
    "char_ids_dev, word_lengths_dev = pad_sequences(char_ids_dev, pad_tok=0, nlevels=2)\n",
    "labels_dev, _ = pad_sequences(labels_dev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "# words, labels = list(minibatches(test, len(test)))[0]  \n",
    "# char_ids, word_ids = zip(*words)\n",
    "# word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
    "# char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0, nlevels=2)\n",
    "# labels, _ = pad_sequences(labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_length = #113 #max(sequence_lengths) None\n",
    "# max_word_length = #24 #max(max(i) for i in word_lengths) #None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5 # needs to be set before Dropout function- GG 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeddings = word_ids, n_words, dim_word\n",
    "# word_emb_input = Input((max_seq_length,))\n",
    "word_emb_input = Input((None,))\n",
    "mask_word = Masking(mask_value=9)(word_emb_input)\n",
    "word_emb_output = Embedding(n_words, dim_word, weights=[embeddings], trainable=False)(mask_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.plaaceholder(tf.float32, (None, None, None))\n",
    "# y = tf.placeholder(tf.float32, (None))\n",
    "# y_reshape = tf.reshape(y, (tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]))\n",
    "# # y_reshape = tf.reshape(y, tf.shape(x)\n",
    "# # y_reshape = tf.reshape(y, (10,  13, 7))\n",
    "# sess = tf.keras.backend.get_session()\n",
    "# xnp = np.random.rand(10, 13, 7)\n",
    "# ynp = xnp.reshape((10*13*7,))\n",
    "# print(xnp.shape)\n",
    "# print(ynp.shape)\n",
    "# print(sess.run(tf.shape(x), feed_dict={x: xnp, y: ynp}))\n",
    "# y_reshape_np = sess.run(y_reshape, feed_dict={x: xnp, y: ynp})\n",
    "# assert np.allclose(xnp, y_reshape_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#end to end paper claims to have applied dropout layer on character embeddings before inputting to a CNN in addition to before both layers of BLSTM\n",
    "# char_emb_input = Input((max_seq_length, max_word_length)) \n",
    "char_emb_input = Input((None, None))\n",
    "#comes in as sentences, words, characters and for the character part we want to just operate it over the character sentence by number of words and seq of characters so reshape so we have words by characters\n",
    "char_emb_output = Lambda(lambda x: tf.keras.backend.reshape(x, (-1, tf.keras.backend.shape(x)[-1])))(char_emb_input)\n",
    "mask_char = Masking(mask_value=9)(char_emb_output)  # TODO: make -1 a variable\n",
    "char_emb_output = Embedding(n_char, dim_char)(mask_char) #need weights here?\n",
    "# 2 sided LSTM below that we can change with forward and backward to see which is better performing\n",
    "# char_emb_output = Bidirectional(LSTM(hidden_size_char, return_sequences=False))(char_emb_output)\n",
    "char_emb_output = Dropout(dropout)(char_emb_output)\n",
    "fw_LSTM = LSTM(hidden_size_char, return_sequences=False)(char_emb_output) #is this right?\n",
    "bw_LSTM = LSTM(hidden_size_char, return_sequences=False, go_backwards=True)(char_emb_output)\n",
    "char_emb_output = concatenate([fw_LSTM, bw_LSTM])\n",
    "char_emb_output = Dropout(dropout)(char_emb_output)\n",
    "char_emb_output = Lambda(lambda x, z: tf.keras.backend.reshape(x, (-1, tf.shape(z)[1], 2 * hidden_size_char)), arguments={\"z\": word_emb_input})(char_emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenates word embedding and character embedding\n",
    "x = concatenate([word_emb_output, char_emb_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(dropout)(x)\n",
    "x = Bidirectional(LSTM(hidden_size_lstm, return_sequences=True))(x)  #should we turn this into two layers (fw and bw)?\n",
    "# fw_LSTM_2 = LSTM(hidden_size_lstm, return_sequences=False)(x) #is this right?\n",
    "# bw_LSTM_2 = LSTM(hidden_size_lstm, return_sequences=False, go_backwards=True)(x)\n",
    "# x = concatenate([fw_LSTM_2, bw_LSTM_2])\n",
    "x = Dropout(dropout)(x)\n",
    "scores = Dense(n_tags)(x) \n",
    "softmax = Activation(\"softmax\")(scores)\n",
    "crf_layer = CRF(n_tags)\n",
    "# crf = crf_layer(scores) #should we add this to attach to the softmax model? with SGD and gradiet clipping of 5.0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax = Model([word_emb_input, char_emb_input], softmax) #should these be input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_softmax = Model(word_emb_input, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf = Model([word_emb_input, char_emb_input], crf) #should these be input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None)         0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    2800        masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 100)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          80400       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100)          80400       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    6900        masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 200)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 500)    0           embedding_1[0][0]                \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 500)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 600)    1922400     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 600)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10)     6010        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 10)     0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,098,910\n",
      "Trainable params: 2,092,010\n",
      "Non-trainable params: 6,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_softmax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'input_2:0' shape=(?, ?, ?) dtype=float32>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_softmax.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_softmax.predict([np.random.randn(10, 100), np.random.randn(10, 100, 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model_softmax).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_op = Adam(lr=lr, decay=lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax.compile(loss=\"categorical_crossentropy\", optimizer=adam_op, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.compile(loss=crf_layer.loss_function, optimizer=adam_op, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ids_arr = np.array(char_ids)\n",
    "word_ids_arr = np.array(word_ids)\n",
    "labels_arr = np.array(labels)\n",
    "# TODO: add one-hot label encoding to function down below\n",
    "labels_arr_one_hot = np.eye(10)[labels] #10 if vocab_tags are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ids_arr_dev = np.array(char_ids_dev)\n",
    "word_ids_arr_dev = np.array(word_ids_dev)\n",
    "labels_arr_dev = np.array(labels_dev)\n",
    "# TODO: add one-hot label encoding to function down below\n",
    "labels_arr_one_hot_dev = np.eye(10)[labels_dev] #10 if vocab_tags are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_ids_arr_dev = np.array(char_ids_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_ids_arr_dev = np.array(word_ids_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_arr_dev = np.array(labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_arr_one_hot_dev = np.eye(9)[labels_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_arr_one_hot_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = datetime.strftime(datetime.today(), \"%y%m%d_%H%M%S\")\n",
    "# base_dir = f\"models/{date}\"\n",
    "# if not os.path.exists(base_dir):\n",
    "#     os.makedirs(base_dir)\n",
    "# model_checkpoint = keras.callbacks.ModelCheckpoint(base_dir + \"/{val_loss}_{epoch:03d}.hdf5\")\n",
    "# tb_callback = keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "# callbacks = [model_checkpoint, tb_callback]\n",
    "# print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 113)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 113, 24)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_ids_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 113, 10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_arr_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing validation_data, it must contain 2 (x_val, y_val) or 3 (x_val, y_val, val_sample_weights) items, however it contains 3250 items",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c9041864fdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# number of epochs without improving is 0 (for early stopping)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# could add gradient clipping (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_ids_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ids_arr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_arr_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;34m'it must contain 2 (x_val, y_val) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0;34m'or 3 (x_val, y_val, val_sample_weights) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             'items, however it contains %d items' % len(validation_data))\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m       val_x, val_y, val_sample_weights = self._standardize_user_data(\n",
      "\u001b[0;31mValueError\u001b[0m: When passing validation_data, it must contain 2 (x_val, y_val) or 3 (x_val, y_val, val_sample_weights) items, however it contains 3250 items"
     ]
    }
   ],
   "source": [
    "# Add callbacks:\n",
    "# early stopping and saving best parameters\n",
    "# learning rate decay\n",
    "# tensorboard\n",
    "# number of epochs without improving is 0 (for early stopping)\n",
    "# could add gradient clipping (optional)\n",
    "model_softmax.fit([word_ids_arr, char_ids_arr], labels_arr_one_hot, batch_size=batch_size, epochs=nepochs, validation_data=dev) \n",
    "#fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "#fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    "\n",
    "# model_softmax.save(f\"{base_dir}/train_softmax.hdf5\") #final_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_softmax.save(\"softmax.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_softmax.save(\"softmax_with_val.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_softmax.save(\"softmax_with_masking_neg1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_softmax.save(\"softmax_with_masking_nine.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax.save(\"softmax_test_5_9.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.fit([word_ids_arr, char_ids_arr], labels_arr_one_hot, batch_size=batch_size, epochs=nepochs, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_crf.save(\"crf.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.save(\"crf_with_val.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir  #models/180222_215523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lolz why so slow?\n",
    "# model_softmax.load_weights(\"softmax_test2.hdf5\") #100 epochs but symptoms of exploding gradients leading me to wanting to add gradient clipping\n",
    "# model_softmax.load_weights(\"softmax_test.hdf5\") #with 75 epochs on same tuning as test2\n",
    "model_softmax.load_weights(\"softmax_test_5_9.hdf5\") #with 75 epochs on same tuning as test2 with dev in training\n",
    "# model_softmax.load_weights(\"softmax_with_masking_nine.hdf5\")\n",
    "# model_softmax.load_weights(\"softmax_with_masking_neg1.hdf5\")\n",
    "# model_softmax.load_weights(f\"{base_dir}/train_softmax.hdf5\")#\"models/180222_215523/final_softmax.hdf5\")#\"0.11342436582348703_050.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need matplotlib\n",
    "# print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_softmax = model_softmax.predict([word_ids_arr, char_ids_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying a test for masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.load_weights(\"crf_with_val.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_crf = model_crf.predict([word_ids_arr, char_ids_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction_crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# scores_crf = model_crf.evaluate([word_ids_arr, char_ids_arr], labels_arr_one_hot) #x_test, y_test (when testing)\n",
    "# print(\"%s: %.2f%%\" % (model_crf.metrics_names[1], scores_crf[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_softmax = model_softmax.evaluate([word_ids_arr, char_ids_arr], labels_arr_one_hot) #x_test, y_test (when testing)\n",
    "# print(\"%s: %.2f%%\" % (model_softmax.metrics_names[1], scores_softmax[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train F1 evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# labels_arr\n",
    "seq_lens_arr = np.array(sequence_lengths)\n",
    "# print(labels_arr[:seq_lens_arr])\n",
    "labels_prob_arr = model_softmax.predict([word_ids_arr, char_ids_arr], batch_size) #shape(num sentences, max num words, num tags)\n",
    "labels_pred_arr = np.argmax(labels_prob_arr, -1)\n",
    "accs = []\n",
    "correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "for lab, lab_pred, seq_len in zip(labels_arr, labels_pred_arr, seq_lens_arr):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "        lab = lab[:seq_len]\n",
    "#         print(lab)\n",
    "#         print(lab.shape)\n",
    "        lab_pred = lab_pred[:seq_len]\n",
    "#         print(lab_pred.shape)\n",
    "#         check_length = np.in1d(seq_len.shape,lab_pred.shape)\n",
    "#         print(check_length)\n",
    "#         unique, counts = np.unique(lab_pred, return_counts=True) #labels are a list not a numpy array\n",
    "#         dict(zip(unique, counts))\n",
    "#         d = dict(zip(unique, counts))\n",
    "#         for i in lab_pred:\n",
    "#             count = 0\n",
    "#         count = 0\n",
    "#         if 0 in lab_pred:\n",
    "#             count = count+1\n",
    "#             print(count)\n",
    "#         else:\n",
    "#             continue\n",
    "        accs += [a==b for (a, b) in zip(lab, lab_pred)]\n",
    "        lab_chunks      = set(get_chunks(lab, vocab_tags))\n",
    "        lab_pred_chunks = set(get_chunks(lab_pred, vocab_tags))\n",
    "#         print(tok)\n",
    "#         print(tags)\n",
    "#         print(seq)\n",
    "        correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "        total_preds   += len(lab_pred_chunks)\n",
    "        total_correct += len(lab_chunks)\n",
    "p   = correct_preds / total_preds if total_preds > 0 else 0 #need something to consider -1s in addition to 0s?\n",
    "r   = correct_preds / total_correct if total_correct > 0 else 0\n",
    "f1  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "acc = np.mean(accs)\n",
    "# unique, counts = np.unique(check_length, return_counts=True) #labels are a list not a numpy array\n",
    "# print(dict(zip(unique, counts)))\n",
    "# print(count)\n",
    "# print(lab_pred)\n",
    "print(acc)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#literally just copying data_utils.py\n",
    "\n",
    "UNK = \"$UNK$\"\n",
    "NUM = \"$NUM$\"\n",
    "NONE = \"O\"\n",
    "\n",
    "# special error message\n",
    "class MyIOError(Exception):\n",
    "    def __init__(self, filename):\n",
    "        # custom error message\n",
    "        message = \"\"\"\n",
    "ERROR: Unable to locate file {}.\n",
    "FIX: Have you tried running python build_data.py first?\n",
    "This will build vocab file from your train, test and dev sets and\n",
    "trimm your word vectors.\n",
    "\"\"\".format(filename)\n",
    "        super(MyIOError, self).__init__(message)\n",
    "\n",
    "\n",
    "class CoNLLDataset(object):\n",
    "    \"\"\"Class that iterates over CoNLL Dataset\n",
    "    __iter__ method yields a tuple (words, tags)\n",
    "        words: list of raw words\n",
    "        tags: list of raw tags\n",
    "    If processing_word and processing_tag are not None,\n",
    "    optional preprocessing is appplied\n",
    "    Example:\n",
    "        ```python\n",
    "        data = CoNLLDataset(filename)\n",
    "        for sentence, tags in data:\n",
    "            pass\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, processing_word=None, processing_tag=None,\n",
    "                 max_iter=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filename: path to the file\n",
    "            processing_words: (optional) function that takes a word as input\n",
    "            processing_tags: (optional) function that takes a tag as input\n",
    "            max_iter: (optional) max number of sentences to yield\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.processing_word = processing_word\n",
    "        self.processing_tag = processing_tag\n",
    "        self.max_iter = max_iter\n",
    "        self.length = None\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        niter = 0\n",
    "        with open(self.filename) as f:\n",
    "            words, tags = [], []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if (len(line) == 0 or line.startswith(\"-DOCSTART-\")):\n",
    "                    if len(words) != 0:\n",
    "                        niter += 1\n",
    "                        if self.max_iter is not None and niter > self.max_iter:\n",
    "                            break\n",
    "                        yield words, tags\n",
    "                        words, tags = [], []\n",
    "                else:\n",
    "                    ls = line.split(' ')\n",
    "                    word, tag = ls[0],ls[-1]\n",
    "                    if self.processing_word is not None:\n",
    "                        word = self.processing_word(word)\n",
    "                    if self.processing_tag is not None:\n",
    "                        tag = self.processing_tag(tag)\n",
    "                    words += [word]\n",
    "                    tags += [tag]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Iterates once over the corpus to set and store length\"\"\"\n",
    "        if self.length is None:\n",
    "            self.length = 0\n",
    "            for _ in self:\n",
    "                self.length += 1\n",
    "\n",
    "        return self.length\n",
    "\n",
    "\n",
    "def get_vocabs(datasets):\n",
    "    \"\"\"Build vocabulary from an iterable of datasets objects\n",
    "    Args:\n",
    "        datasets: a list of dataset objects\n",
    "    Returns:\n",
    "        a set of all the words in the dataset\n",
    "    \"\"\"\n",
    "    print(\"Building vocab...\")\n",
    "    vocab_words = set()\n",
    "    vocab_tags = set()\n",
    "    for dataset in datasets:\n",
    "        for words, tags in dataset:\n",
    "            vocab_words.update(words)\n",
    "            vocab_tags.update(tags)\n",
    "    print(\"- done. {} tokens\".format(len(vocab_words)))\n",
    "    return vocab_words, vocab_tags\n",
    "\n",
    "\n",
    "def get_char_vocab(dataset):\n",
    "    \"\"\"Build char vocabulary from an iterable of datasets objects\n",
    "    Args:\n",
    "        dataset: a iterator yielding tuples (sentence, tags)\n",
    "    Returns:\n",
    "        a set of all the characters in the dataset\n",
    "    \"\"\"\n",
    "    vocab_char = set()\n",
    "    for words, _ in dataset:\n",
    "        for word in words:\n",
    "            vocab_char.update(word)\n",
    "\n",
    "    return vocab_char\n",
    "\n",
    "\n",
    "def get_glove_vocab(filename):\n",
    "    \"\"\"Load vocab from file\n",
    "    Args:\n",
    "        filename: path to the glove vectors\n",
    "    Returns:\n",
    "        vocab: set() of strings\n",
    "    \"\"\"\n",
    "    print(\"Building vocab...\")\n",
    "    vocab = set()\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            word = line.strip().split(' ')[0]\n",
    "            vocab.add(word)\n",
    "    print(\"- done. {} tokens\".format(len(vocab)))\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def write_vocab(vocab, filename):\n",
    "    \"\"\"Writes a vocab to a file\n",
    "    Writes one word per line.\n",
    "    Args:\n",
    "        vocab: iterable that yields word\n",
    "        filename: path to vocab file\n",
    "    Returns:\n",
    "        write a word per line\n",
    "    \"\"\"\n",
    "    print(\"Writing vocab...\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        for i, word in enumerate(vocab):\n",
    "            if i != len(vocab) - 1:\n",
    "                f.write(\"{}\\n\".format(word))\n",
    "            else:\n",
    "                f.write(word)\n",
    "    print(\"- done. {} tokens\".format(len(vocab)))\n",
    "\n",
    "\n",
    "def load_vocab(filename):\n",
    "    \"\"\"Loads vocab from a file\n",
    "    Args:\n",
    "        filename: (string) the format of the file must be one word per line.\n",
    "    Returns:\n",
    "        d: dict[word] = index\n",
    "    \"\"\"\n",
    "    try:\n",
    "        d = dict()\n",
    "        with open(filename) as f:\n",
    "            for idx, word in enumerate(f):\n",
    "                word = word.strip()\n",
    "                d[word] = idx\n",
    "\n",
    "    except IOError:\n",
    "        raise MyIOError(filename)\n",
    "    return d\n",
    "\n",
    "\n",
    "def export_trimmed_glove_vectors(vocab, glove_filename, trimmed_filename, dim):\n",
    "    \"\"\"Saves glove vectors in numpy array\n",
    "    Args:\n",
    "        vocab: dictionary vocab[word] = index\n",
    "        glove_filename: a path to a glove file\n",
    "        trimmed_filename: a path where to store a matrix in npy\n",
    "        dim: (int) dimension of embeddings\n",
    "    \"\"\"\n",
    "    embeddings = np.zeros([len(vocab), dim])\n",
    "    with open(glove_filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(' ')\n",
    "            word = line[0]\n",
    "            embedding = [float(x) for x in line[1:]]\n",
    "            if word in vocab:\n",
    "                word_idx = vocab[word]\n",
    "                embeddings[word_idx] = np.asarray(embedding)\n",
    "\n",
    "    np.savez_compressed(trimmed_filename, embeddings=embeddings)\n",
    "\n",
    "\n",
    "def get_trimmed_glove_vectors(filename):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filename: path to the npz file\n",
    "    Returns:\n",
    "        matrix of embeddings (np array)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with np.load(filename) as data:\n",
    "            return data[\"embeddings\"]\n",
    "\n",
    "    except IOError:\n",
    "        raise MyIOError(filename)\n",
    "\n",
    "\n",
    "def get_processing_word(vocab_words=None, vocab_chars=None,\n",
    "                    lowercase=False, chars=False, allow_unk=True):\n",
    "    \"\"\"Return lambda function that transform a word (string) into list,\n",
    "    or tuple of (list, id) of int corresponding to the ids of the word and\n",
    "    its corresponding characters.\n",
    "    Args:\n",
    "        vocab: dict[word] = idx\n",
    "    Returns:\n",
    "        f(\"cat\") = ([12, 4, 32], 12345)\n",
    "                 = (list of char ids, word id)\n",
    "    \"\"\"\n",
    "    def f(word):\n",
    "        # 0. get chars of words\n",
    "        if vocab_chars is not None and chars == True:\n",
    "            char_ids = []\n",
    "            for char in word:\n",
    "                # ignore chars out of vocabulary\n",
    "                if char in vocab_chars:\n",
    "                    char_ids += [vocab_chars[char]]\n",
    "\n",
    "        # 1. preprocess word\n",
    "        if lowercase:\n",
    "            word = word.lower()\n",
    "        if word.isdigit():\n",
    "            word = NUM\n",
    "\n",
    "        # 2. get id of word\n",
    "        if vocab_words is not None:\n",
    "            if word in vocab_words:\n",
    "                word = vocab_words[word]\n",
    "            else:\n",
    "                if allow_unk:\n",
    "                    word = vocab_words[UNK]\n",
    "                else:\n",
    "                    raise Exception(\"Unknow key is not allowed. Check that \"\\\n",
    "                                    \"your vocab (tags?) is correct\")\n",
    "\n",
    "        # 3. return tuple char ids, word id\n",
    "        if vocab_chars is not None and chars == True:\n",
    "            return char_ids, word\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _pad_sequences(sequences, pad_tok, max_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    sequence_padded, sequence_length = [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        seq = list(seq)\n",
    "        seq_ = seq[:max_length] + [pad_tok]*max(max_length - len(seq), 0)\n",
    "        sequence_padded +=  [seq_]\n",
    "        sequence_length += [min(len(seq), max_length)]\n",
    "\n",
    "    return sequence_padded, sequence_length\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, pad_tok, nlevels=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "        nlevels: \"depth\" of padding, for the case where we have characters ids\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    if nlevels == 1:\n",
    "        max_length = max(map(lambda x : len(x), sequences))\n",
    "        sequence_padded, sequence_length = _pad_sequences(sequences,\n",
    "                                            pad_tok, max_length)\n",
    "\n",
    "    elif nlevels == 2:\n",
    "        max_length_word = max([max(map(lambda x: len(x), seq))\n",
    "                               for seq in sequences])\n",
    "        sequence_padded, sequence_length = [], []\n",
    "        for seq in sequences:\n",
    "            # all words are same length now\n",
    "            sp, sl = _pad_sequences(seq, pad_tok, max_length_word)\n",
    "            sequence_padded += [sp]\n",
    "            sequence_length += [sl]\n",
    "\n",
    "        max_length_sentence = max(map(lambda x : len(x), sequences))\n",
    "        sequence_padded, _ = _pad_sequences(sequence_padded,\n",
    "                [pad_tok]*max_length_word, max_length_sentence)\n",
    "        sequence_length, _ = _pad_sequences(sequence_length, 0,\n",
    "                max_length_sentence)\n",
    "\n",
    "    return sequence_padded, sequence_length\n",
    "\n",
    "\n",
    "def minibatches(data, minibatch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: generator of (sentence, tags) tuples\n",
    "        minibatch_size: (int)\n",
    "    Yields:\n",
    "        list of tuples\n",
    "    \"\"\"\n",
    "    x_batch, y_batch = [], []\n",
    "    for (x, y) in data:\n",
    "        if len(x_batch) == minibatch_size:\n",
    "            yield x_batch, y_batch\n",
    "            x_batch, y_batch = [], []\n",
    "\n",
    "        if type(x[0]) == tuple:\n",
    "            x = zip(*x)\n",
    "        x_batch += [x]\n",
    "        y_batch += [y]\n",
    "\n",
    "    if len(x_batch) != 0:\n",
    "        yield x_batch, y_batch\n",
    "\n",
    "\n",
    "def get_chunk_type(tok, idx_to_tag):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tok: id of token, ex 4\n",
    "        idx_to_tag: dictionary {4: \"B-PER\", ...}\n",
    "    Returns:\n",
    "        tuple: \"B\", \"PER\"\n",
    "    \"\"\"\n",
    "    tag_name = idx_to_tag[tok]\n",
    "    print({\"tag_name\" : tag_name})\n",
    "    tag_class = tag_name.split('-')[0]\n",
    "    print({\"tag_class\" : tag_class})\n",
    "    tag_type = tag_name.split('-')[-1]\n",
    "    print({\"tag_type\" : tag_type})\n",
    "    return tag_class, tag_type\n",
    "\n",
    "\n",
    "def get_chunks(seq, tags):\n",
    "    \"\"\"Given a sequence of tags, group entities and their position\n",
    "    Args:\n",
    "        seq: [4, 4, 0, 0, ...] sequence of labels\n",
    "        tags: dict[\"O\"] = 4\n",
    "    Returns:\n",
    "        list of (chunk_type, chunk_start, chunk_end)\n",
    "    Example:\n",
    "        seq = [4, 5, 0, 3]\n",
    "        tags = {\"B-PER\": 4, \"I-PER\": 5, \"B-LOC\": 3}\n",
    "        result = [(\"PER\", 0, 2), (\"LOC\", 3, 4)]\n",
    "    \"\"\"\n",
    "    default = tags[NONE]\n",
    "    idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
    "    print({\"idx_to_tag\" : idx_to_tag})\n",
    "    chunks = []\n",
    "    chunk_type, chunk_start = None, None\n",
    "    for i, tok in enumerate(seq):\n",
    "        # End of a chunk 1\n",
    "        if tok == default and chunk_type is not None:\n",
    "            # Add a chunk.\n",
    "            chunk = (chunk_type, chunk_start, i)\n",
    "            chunks.append(chunk)\n",
    "            chunk_type, chunk_start = None, None\n",
    "            print({\"chunk\": chunk})\n",
    "\n",
    "        # End of a chunk + start of a chunk!\n",
    "        elif tok != default:\n",
    "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok, idx_to_tag) #get_chunk_type used here\n",
    "            print({\"chunk_type\" : tok_chunk_type})\n",
    "            if chunk_type is None:\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
    "                chunk = (chunk_type, chunk_start, i)\n",
    "                chunks.append(chunk)\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "                print({\"chunk_type\" : chunk_type})\n",
    "                print({\"chunk_start\" : chunk_start})\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # end condition\n",
    "    if chunk_type is not None:\n",
    "        chunk = (chunk_type, chunk_start, len(seq))\n",
    "        chunks.append(chunk)\n",
    "        print({\"chunk\" : chunk})\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####TESTING CODE -- DELETE CELL WHEN FINISHED####\n",
    "\n",
    "# def test_get_chunk_type:\n",
    "#     \"\"\"\n",
    "#     Testing the function get_chunk_type to see if it will work with a non-tag number.\n",
    "#     \"\"\"\n",
    "#     tok\n",
    "# def get_chunk_type(tok, idx_to_tag):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         tok: id of token, ex 4\n",
    "#         idx_to_tag: dictionary {4: \"B-PER\", ...}\n",
    "#     Returns:\n",
    "#         tuple: \"B\", \"PER\"\n",
    "#     \"\"\"\n",
    "#     tag_name = idx_to_tag[tok]\n",
    "#     print({\"tag_name\" : tag_name})\n",
    "#     tag_class = tag_name.split('-')[0]\n",
    "#     print({\"tag_class\" : tag_class})\n",
    "#     tag_type = tag_name.split('-')[-1]\n",
    "#     print({\"tag_type\" : tag_type})\n",
    "#     return tag_class, tag_type\n",
    "\n",
    "seq_lens_arr = np.array(sequence_lengths)\n",
    "# print(labels_arr[:seq_lens_arr])\n",
    "labels_prob_arr = model_softmax.predict([word_ids_arr, char_ids_arr], batch_size) #shape(num sentences, max num words, num tags)\n",
    "labels_pred_arr = np.argmax(labels_prob_arr, -1)\n",
    "accs = []\n",
    "correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "for lab, lab_pred, seq_len in zip(labels_arr, labels_pred_arr, seq_lens_arr):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "        lab = lab[:seq_len]\n",
    "#         print(lab)\n",
    "#         print(lab.shape)\n",
    "        lab_pred = lab_pred[:seq_len]\n",
    "        for n, i in enumerate(lab_pred):\n",
    "                if i == 9:\n",
    "                    lab_pred[n] = 0\n",
    "#         print({\"lab\" : lab})\n",
    "#         print({\"lab type\" : type(lab)})\n",
    "#         print({\"lab_pred type\" : type(lab_pred)})\n",
    "        y_ = lab\n",
    "        y = lab_pred #mycnn(...) # for eg: [2, 2, 4]\n",
    "        num_classes = 9 #change to 9 if can make length of seq_lens_arr\n",
    "\n",
    "        confusion = tf.confusion_matrix(labels=y_, predictions=y, num_classes=num_classes)\n",
    "        print(confusion)\n",
    "\n",
    "#         tok =\n",
    "#         idx_to_tag =\n",
    "#         tag_name = idx_to_tag[tok]\n",
    "#         print({\"tag_name\" : tag_name})\n",
    "#         tag_class = tag_name.split('-')[0]\n",
    "#         print({\"tag_class\" : tag_class})\n",
    "#         tag_type = tag_name.split('-')[-1]\n",
    "#         print({\"tag_type\" : tag_type})\n",
    "#         return tag_class, tag_type\n",
    "\n",
    "# def get_chunks(seq, tags):\n",
    "        \"\"\"Given a sequence of tags, group entities and their position\n",
    "        Args:\n",
    "            seq: [4, 4, 0, 0, ...] sequence of labels\n",
    "            tags: dict[\"O\"] = 4\n",
    "        Returns:\n",
    "            list of (chunk_type, chunk_start, chunk_end)\n",
    "        Example:\n",
    "            seq = [4, 5, 0, 3]\n",
    "            tags = {\"B-PER\": 4, \"I-PER\": 5, \"B-LOC\": 3}\n",
    "            result = [(\"PER\", 0, 2), (\"LOC\", 3, 4)]\n",
    "        \"\"\"\n",
    "#         seq = lab\n",
    "#         tags = vocab_tags\n",
    "#         default = tags[NONE]\n",
    "#         idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
    "#         print({\"idx_to_tag\" : idx_to_tag})\n",
    "#         chunks = []\n",
    "#         chunk_type, chunk_start = None, None\n",
    "#         for i, tok in enumerate(seq):\n",
    "#             # End of a chunk 1\n",
    "#             if tok == default and chunk_type is not None:\n",
    "#                 # Add a chunk.\n",
    "#                 chunk = (chunk_type, chunk_start, i)\n",
    "#                 chunks.append(chunk)\n",
    "#                 chunk_type, chunk_start = None, None\n",
    "#                 print({\"chunk\": chunk})\n",
    "\n",
    "#             # End of a chunk + start of a chunk!\n",
    "#             elif tok != default:\n",
    "#                 tok_chunk_class, tok_chunk_type = get_chunk_type(tok, idx_to_tag) #get_chunk_type used here\n",
    "#                 print({\"chunk_type\" : tok_chunk_type})\n",
    "#                 if chunk_type is None:\n",
    "#                     chunk_type, chunk_start = tok_chunk_type, i\n",
    "#                 elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
    "#                     chunk = (chunk_type, chunk_start, i)\n",
    "#                     chunks.append(chunk)\n",
    "#                     chunk_type, chunk_start = tok_chunk_type, i\n",
    "#                     print({\"chunk_type\" : chunk_type})\n",
    "#                     print({\"chunk_start\" : chunk_start})\n",
    "# #                 print({\"chunk\": chunk})\n",
    "# #                 print({\"chunk_type\" : tok_chunk_type})\n",
    "# #                 print({\"chunk_type\" : chunk_type})\n",
    "# #                 print({\"chunk_start\" : chunk_start})\n",
    "                \n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "            \n",
    "#         # end condition\n",
    "#         if chunk_type is not None:\n",
    "#             chunk = (chunk_type, chunk_start, len(seq))\n",
    "#             chunks.append(chunk)\n",
    "#             print({\"chunk\" : chunk})\n",
    "# #         return chunks\n",
    "\n",
    "words, labels = list(minibatches(train, len(train)))[0]  # NOTE: len(train) will return entire dataset!\n",
    "#GG's version\n",
    "char_ids, word_ids = zip(*words)\n",
    "word_ids, sequence_lengths = pad_sequences(word_ids, pad_tok=9) #word_ids = vocab_chars?\n",
    "char_ids, word_lengths = pad_sequences(char_ids, pad_tok=9, nlevels=2)\n",
    "labels, _ = pad_sequences(labels, pad_tok=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(dataset):\n",
    "    \"\"\"Extract words and labels from a dataset.\n",
    "    \n",
    "    Args:\n",
    "      dataset: A CoNLL dataset.\n",
    "    \n",
    "    Returns:\n",
    "      Word ids, char ids, and labels, from a CoNLL dataset,\n",
    "      all as NumPy arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    words, labels = list(minibatches(dataset, len(dataset)))[0]  # NOTE: len(train) will return entire dataset!\n",
    "    char_ids, word_ids = zip(*words)\n",
    "    # TODO: we need to be able to pad sequences to a specific length\n",
    "    # or the training vs. val vs. test datasets will likely have\n",
    "    # different max lengths not equal to 113\n",
    "    \n",
    "    word_ids, sequence_lengths = pad_sequences(word_ids, pad_tok=9)\n",
    "    char_ids, word_lengths = pad_sequences(char_ids, pad_tok=9, nlevels=2)\n",
    "    labels, _ = pad_sequences(labels, pad_tok=9)\n",
    "\n",
    "#     word_ids, max_seq_length_b = pad_sequences(word_ids, pad_tok=0)\n",
    "#     char_ids, max_word_length_b = pad_sequences(char_ids, pad_tok=0, nlevels=2)\n",
    "#     labels, _ = pad_sequences(labels, pad_tok=0)\n",
    "\n",
    "#     word_ids, sequence_lengths = pad_sequences(word_ids, padding='post', value=0) #word_ids = vocab_chars?\n",
    "#     char_ids, word_lengths = pad_sequences(char_ids, padding='post', value=0, nlevels=2)\n",
    "#     labels, _ = pad_sequences(labels, padding='post', value=0)\n",
    "    word_ids_arr = np.array(word_ids)\n",
    "    char_ids_arr = np.array(char_ids)\n",
    "    labels_arr = np.array(labels)\n",
    "    # TODO: add one-hot encoding of labels\n",
    "    seq_lens_arr = np.array(sequence_lengths)\n",
    "    return word_ids_arr, char_ids_arr, labels_arr, seq_lens_arr\n",
    "\n",
    "\n",
    "def predict_labels(model, word_ids_arr, char_ids_arr, seq_lens_arr, batch_size=32):\n",
    "    \"\"\"Predict labels for a set of words.\n",
    "    \n",
    "    Args:\n",
    "      model: A Keras Model that accepts char ids and word ids\n",
    "        and returns label probs.\n",
    "      word_ids_arr: A NumPy array of word ids for sentences of shape\n",
    "        (num sentences, max num words).\n",
    "      char_ids_arr: A NumPy array of char ids for sentences of shape\n",
    "        (num sentences, max num words, max num chars).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words). \n",
    "    \n",
    "    Returns:\n",
    "      A NumPy array of shape (num sentences, num words)\n",
    "      containing the predicted tags for each word.\n",
    "    \"\"\"\n",
    "#     model.load_weights(\"softmax_with_masking_nine.hdf5\")\n",
    "    labels_prob_arr = model.predict([word_ids_arr, char_ids_arr], batch_size) #shape(num sentences, max num words, num tags)\n",
    "#     labels_prob_arr = model.predict(word_ids_arr, batch_size) #shape(num sentences, max num words, num tags) #DELETE\n",
    "    labels_pred_arr = np.argmax(labels_prob_arr, -1) \n",
    "    return labels_pred_arr\n",
    "\n",
    "\n",
    "def compute_metrics(labels_arr, labels_pred_arr, seq_lens_arr, vocab_tags): #commented out to play with it below but this is the og\n",
    "    \"\"\"Compute accuracy and F1.\n",
    "    \n",
    "    Args:\n",
    "      labels_arr: A NumPy array of correct tags of shape\n",
    "        (num sentences, max num words).\n",
    "      labels_pred_arr: A NumPy array of predicted tags of\n",
    "        shape (num sentences, max num words).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words).\n",
    "      vocab_tags: Dictionary of tag strings to tag numbers.\n",
    "      \n",
    "    Returns:\n",
    "      Dictionary with accuracy `acc` and F1 score `f1`.\n",
    "    \"\"\"\n",
    "    accs = []\n",
    "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "#     import pdb; pdb.set_trace()\n",
    "\n",
    "#     def get_chunk_type(tok, idx_to_tag):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         tok: id of token, ex 4\n",
    "#         idx_to_tag: dictionary {4: \"B-PER\", ...}\n",
    "#     Returns:\n",
    "#         tuple: \"B\", \"PER\"\n",
    "#     \"\"\"\n",
    "#     tag_name = idx_to_tag[tok]\n",
    "#     print(tag_name)\n",
    "#     tag_class = tag_name.split('-')[0]\n",
    "#     tag_type = tag_name.split('-')[-1]\n",
    "#     return tag_class, tag_type\n",
    "    for lab, lab_pred, seq_len in zip(labels_arr, labels_pred_arr, seq_lens_arr):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "        lab = lab[:seq_len]\n",
    "        lab_pred = lab_pred[:seq_len]\n",
    "        for n, i in enumerate(lab_pred):\n",
    "            if i == 9:\n",
    "                lab_pred[n] = 0\n",
    "        \n",
    "        accs += [a==b for (a, b) in zip(lab, lab_pred)]\n",
    "        \n",
    "        # chunk up the labels & predictions by entities (i.e., if there\n",
    "        # are multi-word entities, group those together), and store each\n",
    "        # entity in a tuple\n",
    "        lab_chunks      = set(get_chunks(lab, vocab_tags))\n",
    "#         print({\"lab_chunks\": lab_chunks})\n",
    "#         lab_chunk_type = set(get_chunk_type(lab, vocab_tags))\n",
    "#         print({\"lab_chunk_type\": lab_chunk_type})\n",
    "        lab_pred_chunks = set(get_chunks(lab_pred, vocab_tags))\n",
    "#         print({\"lab_pred_chunks\": lab_pred_chunks})\n",
    "#         lab_pred_chunk_type = set(get_chunk_type(lab_pred, vocab_tags))\n",
    "#         print({\"lab_pred_chunk_type\": lab_pred_chunk_type})\n",
    "\n",
    "        correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "        total_preds   += len(lab_pred_chunks)\n",
    "        total_correct += len(lab_chunks)\n",
    "        \n",
    "#         idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
    "#         print(idx_to_tag)\n",
    "        \n",
    "    p   = correct_preds / total_preds if total_preds > 0 else 0 \n",
    "    r   = correct_preds / total_correct if total_correct > 0 else 0\n",
    "    f1  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "    acc = np.mean(accs)\n",
    "#     y_ = lab\n",
    "#     y = lab_pred #mycnn(...) # for eg: [2, 2, 4]\n",
    "#     num_classes = 9 #change to 9 if can make length of seq_lens_arr\n",
    "\n",
    "#     confusion = tf.confusion_matrix(labels=y_, predictions=y, num_classes=num_classes)\n",
    "#     print({\"confusion\" : confusion})\n",
    "    print ({\"precision\": p})\n",
    "    print ({\"recall\": r})\n",
    "    print ({\"total_correct\": total_correct})\n",
    "    return {\"acc\": 100*acc, \"f1\": 100*f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if in file, could run with `py.test file.py`\n",
    "def test_compute_metrics():\n",
    "    vocab_tags = {\n",
    "        'O': 0,\n",
    "        'B-PER': 1,\n",
    "        'I-PER': 2,\n",
    "        'B-MISC': 3,\n",
    "        'I-MISC': 4,\n",
    "        'B-ORG': 5,\n",
    "        'I-ORG': 6,\n",
    "        'B-LOC': 7,\n",
    "        'I-LOC': 8\n",
    "    }\n",
    "#     vocab_tags = {\n",
    "#             'O': 1,\n",
    "#             'B-PER': 2,\n",
    "#             'I-PER': 3,\n",
    "#             'B-MISC': 4,\n",
    "#             'I-MISC': 5,\n",
    "#             'B-ORG': 6,\n",
    "#             'I-ORG': 7,\n",
    "#             'B-LOC': 8,\n",
    "#             'I-LOC': 9\n",
    "#         }\n",
    "    \n",
    "    def test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn):\n",
    "        metrics = compute_metrics(labels, labels_pred, seq_lens, vocab_tags)\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "        f1 = 2*p*r / (p+r) * 100\n",
    "        assert np.allclose(metrics['acc'], acc), f\"{metrics['acc']}=/={acc}\"\n",
    "        assert np.allclose(metrics['f1'], f1), f\"{metrics['f1']}=/={f1}\"\n",
    "    \n",
    "    # all beginning or null tags\n",
    "    labels = np.array(     [[7, 3, 3], [5, 1, 1, 0]])\n",
    "    labels_pred = np.array([[0, 0, 3], [7, 1, 1, 0]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 4/7 * 100\n",
    "    tp=3\n",
    "    fp=1\n",
    "    fn=3\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "    \n",
    "    # all inside or null tags\n",
    "    labels = np.array(     [[8, 4, 0], [2, 6, 8, 6]])\n",
    "    labels_pred = np.array([[6, 4, 2], [8, 4, 8, 6]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 3/7 * 100\n",
    "    tp=3\n",
    "    fp=4\n",
    "    fn=3\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "    \n",
    "    # all inside or null tags, with multiple insides in a row making a single entity\n",
    "    labels = np.array(     [[8, 4, 0], [2, 2, 8, 6]])\n",
    "    labels_pred = np.array([[6, 4, 2], [8, 4, 8, 6]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 3/7 * 100\n",
    "    tp=3\n",
    "    fp=4\n",
    "    fn=2\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "\n",
    "    # mix of beginning, inside, and null tags, but no multi-word entities\n",
    "    labels = np.array(     [[8, 6, 0], [4, 3, 5, 2]])\n",
    "    labels_pred = np.array([[1, 6, 0], [5, 3, 5, 2]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 5/7 * 100\n",
    "    tp=4\n",
    "    fp=2\n",
    "    fn=2\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "    \n",
    "    # another mix of beginning, inside, and null tags, but no multi-word entities: got rid of 0s and 2s\n",
    "    labels = np.array(     [[8, 6, 4], [4, 3, 5, 0]])\n",
    "    labels_pred = np.array([[1, 6, 4], [5, 3, 5, 3]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 4/7 * 100\n",
    "    tp=4\n",
    "    fp=3\n",
    "    fn=2\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "    \n",
    "    # another mix of beginning, inside, and null tags, but no multi-word entities: exactly the same\n",
    "    labels = np.array(     [[4, 7, 4], [8, 8, 8, 8]]) #mismatched 2s and 0s result in error\n",
    "    labels_pred = np.array([[4, 7, 4], [8, 8, 8, 8]]) #adding matched 2s result in error\n",
    "    seq_lens = np.array([3, 4])\n",
    "    metrics = compute_metrics(labels, labels_pred, seq_lens, vocab_tags)\n",
    "    acc = 7/7 * 100\n",
    "    tp=7\n",
    "    fp=0\n",
    "    fn=0\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "    \n",
    "    # mix of beginning, inside, and null tags, with multi-word entities\n",
    "    labels = np.array(     [[7, 0, 0], [3, 1, 2, 3]])\n",
    "    labels_pred = np.array([[7, 3, 0], [2, 1, 2, 4]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 4/7 * 100\n",
    "    tp=3  #2\n",
    "    fp=2  #3\n",
    "    fn=1  #2\n",
    "#     import pdb; pdb.set_trace()\n",
    "    # THIS APPEARS TO BE A BUG WITH `get_chunks`\n",
    "    # if we look at the second sentence, I printed out the chunked values:\n",
    "    #  ```(Pdb) pp lab\n",
    "    #  [3, 1, 2, 3]\n",
    "    #  (Pdb) pp lab_pred\n",
    "    #  [2, 1, 2, 4]\n",
    "    #  (Pdb) n\n",
    "    #  > <ipython-input-178-11c279c3838c>(76)compute_metrics()\n",
    "    #  -> lab_chunks = set(get_chunks(lab, vocab_tags))\n",
    "    #  (Pdb) n\n",
    "    #  > <ipython-input-178-11c279c3838c>(77)compute_metrics()\n",
    "    #  -> lab_pred_chunks = set(get_chunks(lab_pred, vocab_tags))\n",
    "    #  (Pdb) n\n",
    "    #  > <ipython-input-178-11c279c3838c>(79)compute_metrics()\n",
    "    #  -> correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "    #  (Pdb) pp lab_chunks\n",
    "    #  {('MISC', 0, 1), ('PER', 1, 3), ('MISC', 3, 4)}\n",
    "    #  (Pdb) pp lab_pred_chunks\n",
    "    #  {('PER', 0, 1), ('PER', 1, 3), ('MISC', 3, 4)}\n",
    "    #  (Pdb) pp lab_chunks & lab_pred_chunks\n",
    "    #  {('MISC', 3, 4), ('PER', 1, 3)}\n",
    "    #  ```\n",
    "    # the first words are different (3=MISC vs 2=PER)\n",
    "    # the 2nd & 3rd words form one entity (1=B-PER, 2=I-PER)\n",
    "    # but look at the last words\n",
    "    # 3 = B-MISC, while 4 = I-MISC\n",
    "    # so they should be different\n",
    "    # but the chunking just outputs ('MISC', 3, 4) for both (edited)\n",
    "    # and so it ends up counting that as correct\n",
    "    #\n",
    "    # THE COMMENTED OUT TP/FP/FN VALUES ARE THE ONES THAT SHOULD BE CORRECT,\n",
    "    # BECAUSE THE FINAL WORD IN THE SECOND SENTENCE SHOULD NOT BE CORRECT\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)\n",
    "    \n",
    "    # mix of beginning, inside, and null tags, with multi-word entities\n",
    "    # and multiple inside tags\n",
    "    labels = np.array(     [[7, 0, 0], [3, 1, 2, 3]])\n",
    "    labels_pred = np.array([[3, 2, 2], [2, 1, 2, 4]])\n",
    "    seq_lens = np.array([3, 4])\n",
    "    acc = 2/7 * 100\n",
    "    # SAME ISSUE AS THE PREVIOUS TEST\n",
    "    # THE COMMENTED OUT VALUES ARE THE ONES THAT SHOULD BE CORRECT,\n",
    "    # BECAUSE THE FINAL WORD IN THE SECOND SENTENCE SHOULD NOT BE CORRECT\n",
    "    tp=2  #1\n",
    "    fp=3  #4\n",
    "    fn=2  #3\n",
    "#     import pdb; pdb.set_trace()\n",
    "    test_scenario(labels, labels_pred, seq_lens, acc, tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_tags = {\n",
    "#     'O': 0,\n",
    "#     'B-PER': 1,\n",
    "#     'I-PER': 2,\n",
    "#     'B-MISC': 3,\n",
    "#     'I-MISC': 4,\n",
    "#     'B-ORG': 5,\n",
    "#     'I-ORG': 6,\n",
    "#     'B-LOC': 7,\n",
    "#     'I-LOC': 8\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_compute_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_ids_arr, char_ids_arr, labels_arr, seq_lens_arr = extract_data(train) \n",
    "labels_pred_arr = predict_labels(model_softmax, word_ids_arr, char_ids_arr, seq_lens_arr)\n",
    "metrics = compute_metrics(labels_arr, labels_pred_arr, seq_lens_arr, vocab_tags)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids_arr, char_ids_arr, labels_arr, seq_lens_arr = extract_data(dev) \n",
    "labels_pred_arr = predict_labels(model_softmax, word_ids_arr, char_ids_arr, seq_lens_arr)\n",
    "metrics = compute_metrics(labels_arr, labels_pred_arr, seq_lens_arr, vocab_tags)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [word_ids_arr, char_ids_arr, labels_arr, seq_lens_arr]:\n",
    "    print(a.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dev)\n",
    "dev_array = np.array(dev, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_prob_arr = model_softmax.predict([word_ids_arr, char_ids_arr], batch_size) #shape(num sentences, max num words, num tags)\n",
    "labels_pred_arr = np.argmax(labels_prob_arr, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens_arr = np.array(sequence_lengths)\n",
    "y_ = labels_arr\n",
    "y = labels_pred_arr #mycnn(...) # for eg: [2, 2, 4]\n",
    "num_classes = 9 #change to 9 if can make length of seq_lens_arr\n",
    "\n",
    "confusion = tf.confusion_matrix(labels=y_, predictions=y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_prob_arr[0])\n",
    "print(labels_pred_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_arr[0][:seq_lens_arr[0]])\n",
    "print(labels_prob_arr[0].shape)\n",
    "print(labels_prob_arr[0][:seq_lens_arr[0]])\n",
    "print(np.argmax(labels_prob_arr[0][:seq_lens_arr[0]], axis=-1))\n",
    "# print(np.argmax(labels_prob_arr[0][:seq_lens_arr[0]]))\n",
    "print(labels_pred_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_arr[0])\n",
    "print(labels_arr[0][:seq_lens_arr[0]])\n",
    "print(labels_pred_arr[0])\n",
    "print(labels_pred_arr[0][:seq_lens_arr[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_arr[1])\n",
    "print(labels_arr[1][:seq_lens_arr[1]])\n",
    "print(labels_pred_arr[1])\n",
    "print(labels_pred_arr[1][:seq_lens_arr[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_arr[10])\n",
    "print(labels_arr[10][:seq_lens_arr[10]])\n",
    "print(labels_pred_arr[10])\n",
    "print(labels_pred_arr[10][:seq_lens_arr[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, lab_pred, seq_len in zip (labels_arr, labels_pred_arr, seq_lens_arr):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "    lab = lab[:seq_len]\n",
    "    lab_pred = lab_pred[:seq_len]\n",
    "    for n, i in enumerate(lab_pred):\n",
    "        if i == 0:\n",
    "            lab_pred[n] = 1\n",
    "\n",
    "    print(len(lab_pred))\n",
    "    print(len(lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor only seems to predict 'O' and 'B-PER' tags\n",
    "# labels_pred_seq_lens_arr = (labels_pred_arr[:seq_lens_arr])\n",
    "unique, counts = np.unique(labels_pred_arr, return_counts=True) #labels are a list not a numpy array\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels_arr, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "# type(labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference in \"0s\"\n",
    "print(\"number of incorrect 0 tags: \" )\n",
    "1391215 - 1383012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of incorrect 2 tags: \" )\n",
    "195418- 169578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking total number of incorrect 0 and 2 tags from predicted and comparing to the 1, 3-8 tags of the labels\n",
    "print((8203+25840), (11128+10001+37+8286+4556+24+11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1391215+195418 #total num of pred\n",
    "11128+10001+37+8286+4556+24+11+1383012+169578 # total num of labels (they are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1552590/1586633 #num correct predicted out of total predicted which is the same as total lables (not looking for correct placement just correct number of labels each)\n",
    "#same accuracy as keras evaluation\n",
    "#need to consider placement & chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_placement = np.equal(labels_pred, labels_arr)\n",
    "unique, counts = np.unique(correct_placement, return_counts=True) #labels are a list not a numpy array\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy considering placement is the same as keras evaluation\n",
    "148173/1586633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words, labels = extract_data(train)\n",
    "# labels_pred = predict_labels(words, model_crf)\n",
    "# metrics = compute_metrics(labels, labels_pred, vocab_tags)\n",
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_evaluate(train, model_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def run_evaluate(self, test):\n",
    "        \"\"\"Evaluates performance on test set\n",
    "        Args:\n",
    "            test: dataset that yields tuple of (sentences, tags)\n",
    "        Returns:\n",
    "            metrics: (dict) metrics[\"acc\"] = 98.4, ...\n",
    "        \"\"\"\n",
    "        accs = []\n",
    "        correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "        for words, labels in minibatches(test, self.config.batch_size):\n",
    "            labels_pred, sequence_lengths = self.predict_batch(words)\n",
    "\n",
    "            for lab, lab_pred, length in zip(labels, labels_pred,\n",
    "                                             sequence_lengths):\n",
    "                lab      = lab[:length]\n",
    "                lab_pred = lab_pred[:length]\n",
    "                accs    += [a==b for (a, b) in zip(lab, lab_pred)]\n",
    "\n",
    "                lab_chunks      = set(get_chunks(lab, self.config.vocab_tags))\n",
    "                lab_pred_chunks = set(get_chunks(lab_pred,\n",
    "                                                 self.config.vocab_tags))\n",
    "\n",
    "                correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "                total_preds   += len(lab_pred_chunks)\n",
    "                total_correct += len(lab_chunks)\n",
    "\n",
    "        p   = correct_preds / total_preds if correct_preds > 0 else 0\n",
    "        r   = correct_preds / total_correct if correct_preds > 0 else 0\n",
    "        f1  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "        acc = np.mean(accs)\n",
    "\n",
    "        return {\"acc\": 100*acc, \"f1\": 100*f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evaluate(prediction_softmax, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evaluate(prediction_softmax, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score) #what are these values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- add CRF training (layer + loss)\n",
    "- add different metric\n",
    "- check that training yields same results\n",
    "- should bidirectional lstm use separate forward/backward cells?\n",
    "- clean up notebook\n",
    "- add prediction\n",
    "- check for anything else that's missing\n",
    "- replace code with keras stuff from notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dev_words, dev_labels) in enumerate(minibatches(dev, batch_size)): #len(dev))):\n",
    "    dev_char_ids, dev_word_ids = zip(*dev_words)\n",
    "    dev_word_ids, dev_sequence_lengths = pad_sequences(dev_word_ids,0)\n",
    "    dev_char_ids, dev_word_lengths = pad_sequences(dev_char_ids, pad_tok = 0, nlevels = 2)\n",
    "    dev_labels, _ = pad_sequences(labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_char_ids_arr = np.array(dev_char_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_char_ids_reshape = np.reshape(dev_char_ids_arr, (dev_char_ids_arr.shape[0],dev_char_ids_arr.shape[1] * dev_char_ids_arr.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate([np.array(dev_word_ids), dev_char_ids_reshape], np.array(dev_labels), verbose = 1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"Bob works at IBM in France\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array(tokenizer.texts_to_sequences(test_text)))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_word = get_processing_word(vocab_words, vocab_chars, lowercase=True, chars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [processing_word(w) for w in test_text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ids_arr = []\n",
    "w_ids_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_id or word_ids?\n",
    "for (char_ids, word_id) in words:\n",
    "    c_ids_arr.append(char_ids)\n",
    "    print(word_id)\n",
    "    w_ids_arr.append(word_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ids_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ids_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_char_ids = pad_sequences([c_ids_arr], pad_tok=0, nlevels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_word_ids = pad_sequences([w_ids_arr], pad_tok=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([np.array(pred_char_ids), np.array(pred_word_ids)])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(words[0]) == tuple:\n",
    "    words = zip(*words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(word_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([words])\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

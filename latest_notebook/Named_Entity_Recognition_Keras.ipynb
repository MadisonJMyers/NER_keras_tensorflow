{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from clr_callback import *\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Embedding, Dropout, Bidirectional, LSTM, Concatenate, Reshape, Lambda, Input, Activation, Masking\n",
    "from tensorflow.python.keras.layers import concatenate\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import one_hot\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras_contrib.layers import CRF\n",
    "from model.data_utils import get_trimmed_glove_vectors, load_vocab, get_processing_word, CoNLLDataset, get_trimmed_glove_vectors, load_vocab, get_processing_word, minibatches, get_chunks, pad_sequences\n",
    "from model.ner_model import NERModel\n",
    "from model.config import Config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "#source: https://github.com/synalp/NER\n",
    "train_filename = \"data/coNLL/eng/eng.train.iob\"\n",
    "dev_filename = \"data/coNLL/eng/eng.testa.iob\"\n",
    "test_filename = \"data/coNLL/eng/eng.testb.iob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_chars = True\n",
    "max_iter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this order could be arbitrary, with values in the interval [0, num_tags]\n",
    "# ALSO: there should be a difference between a null tag, and a padded label\n",
    "vocab_tags = load_vocab(\"data/tags.txt\")\n",
    "vocab_chars = load_vocab(\"data/chars.txt\")\n",
    "vocab_words = load_vocab(\"data/words.txt\")\n",
    "n_words = len(vocab_words)\n",
    "n_char = len(vocab_chars)\n",
    "n_tags = (len(vocab_tags)+1) #+1 if different vocab_tags (need to add one for padding of value 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coNLL data for validation\n",
    "dev = CoNLLDataset(dev_filename, get_processing_word(vocab_words, vocab_chars,lowercase=True, chars=use_chars),\n",
    "                  get_processing_word(vocab_tags, lowercase=False, allow_unk=False), max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coNLL data for train\n",
    "train = CoNLLDataset(train_filename, get_processing_word(vocab_words, vocab_chars,lowercase=True, chars=use_chars),\n",
    "                  get_processing_word(vocab_tags, lowercase=False, allow_unk=False), max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coNLL data for test\n",
    "test = CoNLLDataset(test_filename, get_processing_word(vocab_words, vocab_chars,lowercase=True, chars=use_chars),\n",
    "                  get_processing_word(vocab_tags, lowercase=False, allow_unk=False), max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_vocab(filename):\n",
    "    \"\"\"Load vocab from file\n",
    "    Args:\n",
    "        filename: path to the glove vectors\n",
    "    Returns:\n",
    "        vocab: set() of strings\n",
    "    \"\"\"\n",
    "    print(\"Building vocab...\")\n",
    "    vocab = set()\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            word = line.strip().split(' ')[0]\n",
    "            vocab.add(word)\n",
    "    print(\"- done. {} tokens\".format(len(vocab)))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_data = np.load(\"data/glove.6B.300d.trimmed.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = emb_data[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "dim_word = 300 #End to end paper uses 30\n",
    "dim_char = 100\n",
    "hidden_size_char = 100 # lstm on chars\n",
    "hidden_size_lstm = 300 # lstm on word embeddings\n",
    "nepochs = 85 #End to end paper saw best results at 50 epochs\n",
    "lr = 0.0105 #End to end uses learning rate of 0.01 for POS tagging and 0.015 for NER where lr is updated on each epoch with decay rate 0.05\n",
    "lr_decay = 0.0005 #lr/nepochs #0.05 #GG uses 0.9; paper uses 0.05\n",
    "batch_size = 10 #20 #End to end paper uses 10 #eval at 32\n",
    "dropout = 0.5 # needs to be set before Dropout function- GG 0.5\n",
    "### If using SGD instead of Adam:\n",
    "# momentum=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "# TODO: make use of minibatches with fit_generator\n",
    "words, labels = list(minibatches(train, len(train)))[0]  # NOTE: len(train) will return entire dataset!\n",
    "char_ids, word_ids = zip(*words)\n",
    "word_ids, sequence_lengths = pad_sequences(word_ids, pad_tok=9) \n",
    "char_ids, word_lengths = pad_sequences(char_ids, pad_tok=9, nlevels=2)\n",
    "labels, _ = pad_sequences(labels, pad_tok=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation/dev\n",
    "words_dev, labels_dev = list(minibatches(dev, len(dev)))[0]  \n",
    "char_ids_dev, word_ids_dev = zip(*words_dev)\n",
    "word_ids_dev, sequence_lengths_dev = pad_sequences(word_ids_dev, pad_tok=9)\n",
    "char_ids_dev, word_lengths_dev = pad_sequences(char_ids_dev, pad_tok=9, nlevels=2)\n",
    "labels_dev, _ = pad_sequences(labels_dev, pad_tok=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "words_test, labels_test = list(minibatches(test, len(test)))[0]  \n",
    "char_ids_test, word_ids_test = zip(*words_test)\n",
    "word_ids_test, sequence_lengths_test = pad_sequences(word_ids_test, pad_tok=9)\n",
    "char_ids_test, word_lengths_test = pad_sequences(char_ids_test, pad_tok=9, nlevels=2)\n",
    "labels_test, _ = pad_sequences(labels_test, pad_tok=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First 'branch' inputs word embeddings\n",
    "word_emb_input = Input((None,))\n",
    "mask_word = Masking(mask_value=9)(word_emb_input)\n",
    "word_emb_output = Embedding(n_words, dim_word, weights=[embeddings], trainable=False)(mask_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Second 'branch' inputs character embeddings\n",
    "### Note: end to end paper claims to have applied dropout layer on character embeddings before inputting to a CNN in addition to before both layers of BLSTM\n",
    "char_emb_input = Input((None, None))\n",
    "### Reshape: Comes in as sentences, words, characters and for the character part we want to just operate it over the character sentence by \n",
    "### number of words and seq of characters so we reshape so that we have words by characters\n",
    "char_emb_output = Lambda(lambda x: tf.keras.backend.reshape(x, (-1, tf.keras.backend.shape(x)[-1])))(char_emb_input)\n",
    "mask_char = Masking(mask_value=9)(char_emb_output)  # TODO: make -1 a variable\n",
    "char_emb_output = Embedding(n_char, dim_char)(mask_char) #need weights here?\n",
    "char_emb_output = Dropout(dropout)(char_emb_output)\n",
    "### Use bidirectional LSTM or two layers: one forward LSTM, one backward LSTM. Better results with the two layers.\n",
    "char_emb_output = Bidirectional(LSTM(hidden_size_char, return_sequences=False))(char_emb_output)\n",
    "# fw_LSTM = LSTM(hidden_size_char, return_sequences=False)(char_emb_output) \n",
    "# bw_LSTM = LSTM(hidden_size_char, return_sequences=False, go_backwards=True)(char_emb_output)\n",
    "# char_emb_output = concatenate([fw_LSTM, bw_LSTM])\n",
    "### Use dropout to prevent overfitting (as a regularizer)\n",
    "char_emb_output = Dropout(dropout)(char_emb_output)\n",
    "### Reshape back\n",
    "char_emb_output = Lambda(lambda x, z: tf.keras.backend.reshape(x, (-1, tf.shape(z)[1], 2 * hidden_size_char)), arguments={\"z\": word_emb_input})(char_emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenates word embedding and character embedding\n",
    "x = concatenate([word_emb_output, char_emb_output])\n",
    "x = Dropout(dropout)(x)\n",
    "### Use bidirectional LSTM or two layers: one forward LSTM, one backward LSTM. Better results with bidirectional LSTM here.\n",
    "x = Bidirectional(LSTM(hidden_size_lstm, return_sequences=True))(x)  #should we turn this into two layers (fw and bw)?\n",
    "# fw_LSTM_2 = LSTM(hidden_size_lstm, return_sequences=True)(x) #is this right?\n",
    "# bw_LSTM_2 = LSTM(hidden_size_lstm, return_sequences=True, go_backwards=True)(fw_LSTM_2)\n",
    "# x = concatenate([fw_LSTM_2, bw_LSTM_2])\n",
    "### Use dropout to prevent overfitting (as a regularizer)\n",
    "x = Dropout(dropout)(x)\n",
    "scores = Dense(n_tags)(x)\n",
    "### Activation Function\n",
    "softmax = Activation(\"softmax\")(scores)\n",
    "### If implementing CRF\n",
    "# crf_layer = CRF(n_tags)\n",
    "# crf = crf_layer(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax = Model([word_emb_input, char_emb_input], softmax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf = Model([word_emb_input, char_emb_input], crf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizers: Adam shows best results\n",
    "adam_op = Adam(lr=lr, decay=lr_decay)\n",
    "# sgd = SGD(lr=lr, momentum=momentum, decay=lr_decay)\n",
    "# adagrad = Adagrad(lr=0.0105, epsilon=None, decay=0.0005)\n",
    "# rms = RMSprop(lr=0.0105, rho=0.9, epsilon=None, decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax.compile(optimizer=adam_op, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.compile(loss=crf_layer.loss_function, optimizer=adam_op, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to NumPy Arrays and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### put into numpy arrays and put labels into one hot encoding\n",
    "#train\n",
    "char_ids_arr = np.array(char_ids)\n",
    "word_ids_arr = np.array(word_ids)\n",
    "labels_arr = np.array(labels)\n",
    "labels_arr_one_hot = np.eye(10)[labels] #10 if vocab_tags are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev/validation\n",
    "char_ids_arr_dev = np.array(char_ids_dev)\n",
    "word_ids_arr_dev = np.array(word_ids_dev)\n",
    "labels_arr_dev = np.array(labels_dev)\n",
    "labels_arr_one_hot_dev = np.eye(10)[labels_dev] #10 if vocab_tags are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "char_ids_arr_test = np.array(char_ids_test)\n",
    "word_ids_arr_test = np.array(word_ids_test)\n",
    "labels_arr_test = np.array(labels_test)\n",
    "labels_arr_one_hot_test = np.eye(10)[labels_test] #10 if vocab_tags are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional: Early Stopping and Callbacks\n",
    "# date = datetime.strftime(datetime.today(), \"%y%m%d_%H%M%S\")\n",
    "# base_dir = f\"models/{date}\"\n",
    "# if not os.path.exists(base_dir):\n",
    "#     os.makedirs(base_dir)\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(base_dir + \"/{val_loss}_{epoch:03d}.hdf5\")\n",
    "### Add callbacks to tensorboard\n",
    "# # tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "# callbacks = [model_checkpoint] #, tb_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model and Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit model.\n",
    "model_softmax.fit([word_ids_arr, char_ids_arr], labels_arr_one_hot, batch_size=batch_size, epochs=nepochs, validation_data=([word_ids_arr_dev, char_ids_arr_dev], labels_arr_one_hot_dev)) # validation_data=([word_ids_arr_dev, char_ids_arr_dev], labels_arr_one_hot_dev) OR validation_split=0.3\n",
    "### Parameters for reference:\n",
    "### fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "# model_softmax.save(f\"{base_dir}/train_softmax.hdf5\") #final_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax.save_weights(\"softmax_test_6_17.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.fit([word_ids_arr, char_ids_arr], labels_arr_one_hot, batch_size=batch_size, epochs=nepochs, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.save(\"crf.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_softmax.load_weights(\"softmax_test_6_17.hdf5\")\n",
    "# model_softmax.load_weights(f\"{base_dir}/train_softmax.hdf5\")#\"models/180222_215523/final_softmax.hdf5\")#\"0.11342436582348703_050.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_crf.load_weights(\"crf_with_val.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on train, dev and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate Training##\n",
    "def extract_data(dataset):\n",
    "    \"\"\"Extract words and labels from a dataset.\n",
    "    \n",
    "    Args:\n",
    "      dataset: A CoNLL dataset.\n",
    "    \n",
    "    Returns:\n",
    "      Word ids, char ids, and labels, from a CoNLL dataset,\n",
    "      all as NumPy arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    words, labels = list(minibatches(dataset, len(dataset)))[0]  # NOTE: len(train) will return entire dataset!\n",
    "    char_ids, word_ids = zip(*words)\n",
    "    \n",
    "    word_ids, sequence_lengths = pad_sequences(word_ids, pad_tok=9)\n",
    "    char_ids, word_lengths = pad_sequences(char_ids, pad_tok=9, nlevels=2)\n",
    "    labels, _ = pad_sequences(labels, pad_tok=9)\n",
    "\n",
    "    word_ids_arr = np.array(word_ids)\n",
    "    char_ids_arr = np.array(char_ids)\n",
    "    labels_arr = np.array(labels)\n",
    "    # TODO: add one-hot encoding of labels\n",
    "    seq_lens_arr = np.array(sequence_lengths)\n",
    "    return word_ids_arr, char_ids_arr, labels_arr, seq_lens_arr\n",
    "\n",
    "\n",
    "def predict_labels(model, word_ids_arr, char_ids_arr, seq_lens_arr, batch_size=32):\n",
    "    \"\"\"Predict labels for a set of words.\n",
    "    \n",
    "    Args:\n",
    "      model: A Keras Model that accepts char ids and word ids\n",
    "        and returns label probs.\n",
    "      word_ids_arr: A NumPy array of word ids for sentences of shape\n",
    "        (num sentences, max num words).\n",
    "      char_ids_arr: A NumPy array of char ids for sentences of shape\n",
    "        (num sentences, max num words, max num chars).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words). \n",
    "    \n",
    "    Returns:\n",
    "      A NumPy array of shape (num sentences, num words)\n",
    "      containing the predicted tags for each word.\n",
    "    \"\"\"\n",
    "#     model.load_weights(\"softmax_with_masking_nine.hdf5\")\n",
    "    labels_prob_arr = model.predict([word_ids_arr, char_ids_arr], batch_size) #shape(num sentences, max num words, num tags)\n",
    "#     labels_prob_arr = model.predict(word_ids_arr, batch_size) #shape(num sentences, max num words, num tags) #DELETE\n",
    "    labels_pred_arr = np.argmax(labels_prob_arr, -1) \n",
    "    return labels_pred_arr\n",
    "\n",
    "\n",
    "def compute_metrics(labels_arr, labels_pred_arr, seq_lens_arr, vocab_tags): #commented out to play with it below but this is the og\n",
    "    \"\"\"Compute accuracy and F1.\n",
    "    \n",
    "    Args:\n",
    "      labels_arr: A NumPy array of correct tags of shape\n",
    "        (num sentences, max num words).\n",
    "      labels_pred_arr: A NumPy array of predicted tags of\n",
    "        shape (num sentences, max num words).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words).\n",
    "      vocab_tags: Dictionary of tag strings to tag numbers.\n",
    "      \n",
    "    Returns:\n",
    "      Dictionary with accuracy `acc` and F1 score `f1`.\n",
    "    \"\"\"\n",
    "    accs = []\n",
    "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "\n",
    "    for lab, lab_pred, seq_len in zip(labels_arr, labels_pred_arr, seq_lens_arr):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "        lab = lab[:seq_len]\n",
    "        lab_pred = lab_pred[:seq_len]\n",
    "        for n, i in enumerate(lab_pred):\n",
    "            if i == 9:\n",
    "                lab_pred[n] = 0\n",
    "        \n",
    "        accs += [a==b for (a, b) in zip(lab, lab_pred)]\n",
    "        \n",
    "        lab_chunks      = set(get_chunks(lab, vocab_tags))\n",
    "        lab_pred_chunks = set(get_chunks(lab_pred, vocab_tags))\n",
    "\n",
    "        correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "        total_preds   += len(lab_pred_chunks)\n",
    "        total_correct += len(lab_chunks)\n",
    "\n",
    "        \n",
    "    p   = correct_preds / total_preds if total_preds > 0 else 0 \n",
    "    r   = correct_preds / total_correct if total_correct > 0 else 0\n",
    "    f1  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "    acc = np.mean(accs)\n",
    "\n",
    "    print ({\"precision\": p})\n",
    "    print ({\"recall\": r})\n",
    "    print ({\"total_correct\": total_correct})\n",
    "    return {\"acc\": 100*acc, \"f1\": 100*f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_ids_arr, char_ids_arr, labels_arr, seq_lens_arr = extract_data(train) \n",
    "labels_pred_arr = predict_labels(model_softmax, word_ids_arr, char_ids_arr, seq_lens_arr)\n",
    "metrics = compute_metrics(labels_arr, labels_pred_arr, seq_lens_arr, vocab_tags)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate Dev##\n",
    "def extract_data(dataset):\n",
    "    \"\"\"Extract words and labels from a dataset.\n",
    "    \n",
    "    Args:\n",
    "      dataset: A CoNLL dataset.\n",
    "    \n",
    "    Returns:\n",
    "      Word ids, char ids, and labels, from a CoNLL dataset,\n",
    "      all as NumPy arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    #validation/dev\n",
    "    words_dev, labels_dev = list(minibatches(dev, len(dev)))[0]  \n",
    "    char_ids_dev, word_ids_dev = zip(*words_dev)\n",
    "    word_ids_dev, sequence_lengths_dev = pad_sequences(word_ids_dev, pad_tok=9)\n",
    "    char_ids_dev, word_lengths_dev = pad_sequences(char_ids_dev, pad_tok=9, nlevels=2)\n",
    "    labels_dev, _ = pad_sequences(labels_dev, pad_tok=9)\n",
    "\n",
    "    \n",
    "    word_ids_arr_dev = np.array(word_ids_dev)\n",
    "    char_ids_arr_dev = np.array(char_ids_dev)\n",
    "    labels_arr_dev = np.array(labels_dev)\n",
    "    # TODO: add one-hot encoding of labels\n",
    "    seq_lens_arr_dev = np.array(sequence_lengths_dev)\n",
    "    return word_ids_arr_dev, char_ids_arr_dev, labels_arr_dev, seq_lens_arr_dev\n",
    "\n",
    "\n",
    "def predict_labels(model, word_ids_arr_dev, char_ids_arr_dev, seq_lens_arr_dev, batch_size=32):\n",
    "    \"\"\"Predict labels for a set of words.\n",
    "    \n",
    "    Args:\n",
    "      model: A Keras Model that accepts char ids and word ids\n",
    "        and returns label probs.\n",
    "      word_ids_arr: A NumPy array of word ids for sentences of shape\n",
    "        (num sentences, max num words).\n",
    "      char_ids_arr: A NumPy array of char ids for sentences of shape\n",
    "        (num sentences, max num words, max num chars).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words). \n",
    "    \n",
    "    Returns:\n",
    "      A NumPy array of shape (num sentences, num words)\n",
    "      containing the predicted tags for each word.\n",
    "    \"\"\"\n",
    "#     model.load_weights(\"softmax_with_masking_nine.hdf5\")\n",
    "    labels_prob_arr_dev = model.predict([word_ids_arr_dev, char_ids_arr_dev], batch_size) #shape(num sentences, max num words, num tags)\n",
    "#     labels_prob_arr = model.predict(word_ids_arr, batch_size) #shape(num sentences, max num words, num tags) #DELETE\n",
    "    labels_pred_arr_dev = np.argmax(labels_prob_arr_dev, -1) \n",
    "    return labels_pred_arr_dev\n",
    "\n",
    "\n",
    "def compute_metrics(labels_arr_dev, labels_pred_arr_dev, seq_lens_arr_dev, vocab_tags): #commented out to play with it below but this is the og\n",
    "    \"\"\"Compute accuracy and F1.\n",
    "    \n",
    "    Args:\n",
    "      labels_arr: A NumPy array of correct tags of shape\n",
    "        (num sentences, max num words).\n",
    "      labels_pred_arr: A NumPy array of predicted tags of\n",
    "        shape (num sentences, max num words).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words).\n",
    "      vocab_tags: Dictionary of tag strings to tag numbers.\n",
    "      \n",
    "    Returns:\n",
    "      Dictionary with accuracy `acc` and F1 score `f1`.\n",
    "    \"\"\"\n",
    "    accs_dev = []\n",
    "    correct_preds_dev, total_correct_dev, total_preds_dev = 0., 0., 0.\n",
    "\n",
    "    for lab_dev, lab_pred_dev, seq_len_dev in zip(labels_arr_dev, labels_pred_arr_dev, seq_lens_arr_dev):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "        lab_dev = lab_dev[:seq_len_dev]\n",
    "        lab_pred_dev = lab_pred_dev[:seq_len_dev]\n",
    "        for n, i in enumerate(lab_pred_dev):\n",
    "            if i == 9:\n",
    "                lab_pred_dev[n] = 0\n",
    "        \n",
    "        accs_dev += [a==b for (a, b) in zip(lab_dev, lab_pred_dev)]\n",
    "\n",
    "        lab_chunks_dev = set(get_chunks(lab_dev, vocab_tags))\n",
    "        lab_pred_chunks_dev = set(get_chunks(lab_pred_dev, vocab_tags))\n",
    "\n",
    "        correct_preds_dev += len(lab_chunks_dev & lab_pred_chunks_dev)\n",
    "        total_preds_dev   += len(lab_pred_chunks_dev)\n",
    "        total_correct_dev += len(lab_chunks_dev)\n",
    "        \n",
    "    p_dev   = correct_preds_dev / total_preds_dev if total_preds_dev > 0 else 0 \n",
    "    r_dev   = correct_preds_dev / total_correct_dev if total_correct_dev > 0 else 0\n",
    "    f1_dev  = 2 * p_dev * r_dev / (p_dev + r_dev) if correct_preds_dev > 0 else 0\n",
    "    acc_dev = np.mean(accs_dev)\n",
    "\n",
    "    print ({\"precision\": p_dev})\n",
    "    print ({\"recall\": r_dev})\n",
    "    print ({\"total_correct\": total_correct_dev})\n",
    "    return {\"acc\": 100*acc_dev, \"f1\": 100*f1_dev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev\n",
    "word_ids_arr_dev, char_ids_arr_dev, labels_arr_dev, seq_lens_arr_dev = extract_data(dev) \n",
    "labels_pred_arr_dev = predict_labels(model_softmax, word_ids_arr_dev, char_ids_arr_dev, seq_lens_arr_dev)\n",
    "metrics = compute_metrics(labels_arr_dev, labels_pred_arr_dev, seq_lens_arr_dev, vocab_tags)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate Test##\n",
    "def extract_data(dataset):\n",
    "    \"\"\"Extract words and labels from a dataset.\n",
    "    \n",
    "    Args:\n",
    "      dataset: A CoNLL dataset.\n",
    "    \n",
    "    Returns:\n",
    "      Word ids, char ids, and labels, from a CoNLL dataset,\n",
    "      all as NumPy arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    #test\n",
    "    words_test, labels_test = list(minibatches(test, len(test)))[0]  \n",
    "    char_ids_test, word_ids_test = zip(*words_test)\n",
    "    word_ids_test, sequence_lengths_test = pad_sequences(word_ids_test, pad_tok=9)\n",
    "    char_ids_test, word_lengths_test = pad_sequences(char_ids_test, pad_tok=9, nlevels=2)\n",
    "    labels_test, _ = pad_sequences(labels_test, pad_tok=9)\n",
    "    \n",
    "    word_ids_arr_test = np.array(word_ids_test)\n",
    "    char_ids_arr_test = np.array(char_ids_test)\n",
    "    labels_arr_test = np.array(labels_test)\n",
    "    # TODO: add one-hot encoding of labels\n",
    "    seq_lens_arr_test = np.array(sequence_lengths_test)\n",
    "    return word_ids_arr_test, char_ids_arr_test, labels_arr_test, seq_lens_arr_test\n",
    "\n",
    "\n",
    "def predict_labels(model, word_ids_arr_test, char_ids_arr_test, seq_lens_arr_test, batch_size=32):\n",
    "    \"\"\"Predict labels for a set of words.\n",
    "    \n",
    "    Args:\n",
    "      model: A Keras Model that accepts char ids and word ids\n",
    "        and returns label probs.\n",
    "      word_ids_arr: A NumPy array of word ids for sentences of shape\n",
    "        (num sentences, max num words).\n",
    "      char_ids_arr: A NumPy array of char ids for sentences of shape\n",
    "        (num sentences, max num words, max num chars).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words). \n",
    "    \n",
    "    Returns:\n",
    "      A NumPy array of shape (num sentences, num words)\n",
    "      containing the predicted tags for each word.\n",
    "    \"\"\"\n",
    "#     model.load_weights(\"softmax_with_masking_nine.hdf5\")\n",
    "    labels_prob_arr_test = model.predict([word_ids_arr_test, char_ids_arr_test], batch_size) #shape(num sentences, max num words, num tags)\n",
    "#     labels_prob_arr = model.predict(word_ids_arr, batch_size) #shape(num sentences, max num words, num tags) #DELETE\n",
    "    labels_pred_arr_test = np.argmax(labels_prob_arr_test, -1) \n",
    "    return labels_pred_arr_test\n",
    "\n",
    "\n",
    "def compute_metrics(labels_arr_test, labels_pred_arr_test, seq_lens_arr_test, vocab_tags): #commented out to play with it below but this is the og\n",
    "    \"\"\"Compute accuracy and F1.\n",
    "    \n",
    "    Args:\n",
    "      labels_arr: A NumPy array of correct tags of shape\n",
    "        (num sentences, max num words).\n",
    "      labels_pred_arr: A NumPy array of predicted tags of\n",
    "        shape (num sentences, max num words).\n",
    "      seq_lens_arr: A NumPy array of sentence lengths, of\n",
    "        shape (num sentences, actual num words).\n",
    "      vocab_tags: Dictionary of tag strings to tag numbers.\n",
    "      \n",
    "    Returns:\n",
    "      Dictionary with accuracy `acc` and F1 score `f1`.\n",
    "    \"\"\"\n",
    "    accs_test = []\n",
    "    correct_preds_test, total_correct_test, total_preds_test = 0., 0., 0.\n",
    "\n",
    "    for lab_test, lab_pred_test, seq_len_test in zip(labels_arr_test, labels_pred_arr_test, seq_lens_arr_test):\n",
    "        # NOTE: labels & predictions are padded to the maximum number of words\n",
    "        # in the batch.  Here, we use the actual sentence lengths to select out\n",
    "        # the actual labels and corresponding predictions.\n",
    "        lab_test = lab_test[:seq_len_test]\n",
    "        lab_pred_test = lab_pred_test[:seq_len_test]\n",
    "        for n, i in enumerate(lab_pred_test):\n",
    "            if i == 9:\n",
    "                lab_pred_test[n] = 0\n",
    "        \n",
    "        accs_test += [a==b for (a, b) in zip(lab_test, lab_pred_test)]\n",
    "\n",
    "        lab_chunks_test = set(get_chunks(lab_test, vocab_tags))\n",
    "        lab_pred_chunks_test = set(get_chunks(lab_pred_test, vocab_tags))\n",
    "\n",
    "        correct_preds_test += len(lab_chunks_test & lab_pred_chunks_test)\n",
    "        total_preds_test   += len(lab_pred_chunks_test)\n",
    "        total_correct_test += len(lab_chunks_test)\n",
    "        \n",
    "    p_test   = correct_preds_test / total_preds_test if total_preds_test > 0 else 0 \n",
    "    r_test   = correct_preds_test / total_correct_test if total_correct_test > 0 else 0\n",
    "    f1_test  = 2 * p_test * r_test / (p_test + r_test) if correct_preds_test > 0 else 0\n",
    "    acc_test = np.mean(accs_test)\n",
    "\n",
    "    print ({\"precision\": p_test})\n",
    "    print ({\"recall\": r_test})\n",
    "    print ({\"total_correct\": total_correct_test})\n",
    "    return {\"acc\": 100*acc_test, \"f1\": 100*f1_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "word_ids_arr_test, char_ids_arr_test, labels_arr_test, seq_lens_arr_test = extract_data(test) \n",
    "labels_pred_arr_test = predict_labels(model_softmax, word_ids_arr_test, char_ids_arr_test, seq_lens_arr_test)\n",
    "metrics = compute_metrics(labels_arr_test, labels_pred_arr_test, seq_lens_arr_test, vocab_tags)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To Do: Add interactive shell\n",
    "###Trial to try to have interactive shell\n",
    "#From evaluate.py in GG's code:\n",
    "def align_data(data):\n",
    "    \"\"\"Given dict with lists, creates aligned strings\n",
    "    Adapted from Assignment 3 of CS224N\n",
    "    Args:\n",
    "        data: (dict) data[\"x\"] = [\"I\", \"love\", \"you\"]\n",
    "              (dict) data[\"y\"] = [\"O\", \"O\", \"O\"]\n",
    "    Returns:\n",
    "        data_aligned: (dict) data_align[\"x\"] = \"I love you\"\n",
    "                           data_align[\"y\"] = \"O O    O  \"\n",
    "    \"\"\"\n",
    "    spacings = [max([len(seq[i]) for seq in data.values()])\n",
    "                for i in range(len(data[list(data.keys())[0]]))]\n",
    "    data_aligned = dict()\n",
    "\n",
    "    # for each entry, create aligned string\n",
    "    for key, seq in data.items():\n",
    "        str_aligned = \"\"\n",
    "        for token, spacing in zip(seq, spacings):\n",
    "            str_aligned += token + \" \" * (spacing - len(token) + 1)\n",
    "\n",
    "        data_aligned[key] = str_aligned\n",
    "\n",
    "    return data_aligned\n",
    "\n",
    "\n",
    "\n",
    "def interactive_shell(model):\n",
    "    \"\"\"Creates interactive shell to play with model\n",
    "    Args:\n",
    "        model: instance of NERModel\n",
    "    \"\"\"\n",
    "#     model.logger.info(\"\"\"\n",
    "# This is an interactive mode.\n",
    "# To exit, enter 'exit'.\n",
    "# You can enter a sentence like\n",
    "# input> I love Paris\"\"\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # for python 2\n",
    "            sentence = raw_input(\"input> \")\n",
    "        except NameError:\n",
    "            # for python 3\n",
    "            sentence = input(\"input> \")\n",
    "\n",
    "        words_raw = sentence.strip().split(\" \")\n",
    "#         print(words_raw)\n",
    "\n",
    "        if words_raw == [\"exit\"]:\n",
    "            break\n",
    "\n",
    "        preds = model.predict(words_raw)\n",
    "#         to_print = align_data({\"input\": words_raw, \"output\": preds})\n",
    "        print({\"input\": words_raw, \"output\": preds})\n",
    "\n",
    "#         for key, seq in to_print.items():\n",
    "#             model.logger.info(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_shell(model_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
